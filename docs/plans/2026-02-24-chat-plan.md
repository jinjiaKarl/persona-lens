# Chat Feature Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Add a side-by-side chat panel to the frontend that connects to the existing Python Agent (OpenAI Agents SDK), streams token-by-token responses, and automatically updates the analysis panel when the Agent fetches/analyzes a user.

**Architecture:** A new `POST /api/chat` FastAPI endpoint wraps `Runner.run_streamed(main_agent, ...)` and emits SSE events: `token` (text deltas), `tool_call` (agent tool activity), `analysis_result` (structured data to update left panel), and `done`. A global `AgentContext` + `SQLAlchemySession` persists conversation memory across HTTP requests (single-user phase). The frontend page is restructured as left 60% analysis panel + right 40% chat panel; mobile uses tab switching.

**Tech Stack:** Python: FastAPI, sse-starlette, openai-agents, sqlalchemy+aiosqlite. Frontend: Next.js 16, React 19, Tailwind CSS v4, shadcn/ui.

---

## Task 1: Backend — add `/api/chat` endpoint

**Files:**
- Modify: `persona_lens/api/server.py`

**Context:** The existing `loop.py` shows how to use `Runner.run_streamed` with `main_agent`. Key imports: `from agents import Runner`, `from openai.types.responses import ResponseTextDeltaEvent`. The `AgentContext` is the shared cache. `SQLAlchemySession` provides conversation memory (multi-turn).

**Step 1: Read current server.py to confirm starting state**

Run:
```bash
cat persona_lens/api/server.py
```

**Step 2: Replace server.py with the updated version**

Replace the full contents of `persona_lens/api/server.py`:

```python
"""FastAPI server exposing persona_lens analysis as SSE endpoints."""
import json
import os
from typing import AsyncGenerator

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from sse_starlette.sse import EventSourceResponse
from sqlalchemy.ext.asyncio import create_async_engine

from agents import Runner
from agents.extensions.memory import SQLAlchemySession
from openai.types.responses import ResponseTextDeltaEvent

from persona_lens.agent.context import AgentContext
from persona_lens.agent.loop import main_agent
from persona_lens.platforms.x.fetcher import fetch_snapshot
from persona_lens.platforms.x.parser import extract_tweet_data, extract_user_info
from persona_lens.platforms.x.analyzer import analyze_user_profile
from persona_lens.utils.patterns import compute_posting_patterns

app = FastAPI(title="persona-lens API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_methods=["GET", "POST"],
    allow_headers=["*"],
)

# ── Single-user session state (phase 1) ─────────────────────────────────────
# get_context() returns the global singleton.
# To migrate to multi-tenant: replace get_context() to look up by session_id.

_global_ctx = AgentContext()
_engine = create_async_engine("sqlite+aiosqlite:///:memory:")
_chat_session: SQLAlchemySession | None = None


def get_context(session_id: str) -> AgentContext:
    """Return AgentContext for the given session. Single-user: always global."""
    return _global_ctx


async def get_chat_session() -> SQLAlchemySession:
    """Return the shared SQLAlchemy session (creates tables on first call)."""
    global _chat_session
    if _chat_session is None:
        _chat_session = SQLAlchemySession(
            "web-chat", engine=_engine, create_tables=True
        )
    return _chat_session


# ── Endpoints ────────────────────────────────────────────────────────────────

@app.get("/api/health")
def health():
    """Check that required env vars are set."""
    if not os.getenv("OPENAI_API_KEY"):
        raise HTTPException(status_code=503, detail="OPENAI_API_KEY not set")
    return {"status": "ok"}


@app.post("/api/analyze/{username}")
async def analyze(username: str, tweets: int = 30):
    """Stream SSE events: progress stages then final result."""
    username = username.lstrip("@")

    async def _generate() -> AsyncGenerator[dict, None]:
        try:
            yield {
                "event": "progress",
                "data": json.dumps({"stage": "fetching", "message": "Fetching tweets\u2026"}),
            }
            snapshot = fetch_snapshot(username, tweet_count=tweets)
            all_tweets = extract_tweet_data(snapshot)
            user_tweets = [
                t for t in all_tweets
                if t.get("author") is None
                or t["author"].lstrip("@").lower() == username.lower()
            ]

            yield {
                "event": "progress",
                "data": json.dumps({
                    "stage": "parsing",
                    "message": f"Parsed {len(user_tweets)} tweets\u2026",
                }),
            }
            user_info = extract_user_info(snapshot, username)
            patterns = compute_posting_patterns(user_tweets)

            yield {
                "event": "progress",
                "data": json.dumps({"stage": "analyzing", "message": "Running AI analysis\u2026"}),
            }
            profile = await analyze_user_profile(username, user_tweets)

            result = {
                "user_info": user_info,
                "tweets": user_tweets,
                "patterns": patterns,
                "analysis": profile,
            }
            yield {"event": "result", "data": json.dumps(result, ensure_ascii=False)}

        except Exception as exc:
            msg = str(exc)
            fix = ""
            if "9377" in msg or "camofox" in msg.lower() or "Connection" in msg:
                fix = "Start Camofox Browser: cd camofox-browser && npm start"
            elif "OPENAI_API_KEY" in msg:
                fix = "Set OPENAI_API_KEY in your .env file"
            yield {
                "event": "error",
                "data": json.dumps({"error": msg, "fix": fix}),
            }

    return EventSourceResponse(_generate())


class ChatRequest(BaseModel):
    message: str
    session_id: str = "default"


@app.post("/api/chat")
async def chat(req: ChatRequest):
    """Stream chat responses from the main agent via SSE."""
    ctx = get_context(req.session_id)
    session = await get_chat_session()

    async def _generate() -> AsyncGenerator[dict, None]:
        # Snapshot which users are already analyzed before this turn
        before_analyses: set[str] = set(ctx.analysis_cache.get("x", {}).keys())

        try:
            result = Runner.run_streamed(
                main_agent,
                input=req.message,
                context=ctx,
                session=session,
            )

            async for event in result.stream_events():
                # Stream text tokens
                if event.type == "raw_response_event":
                    if isinstance(event.data, ResponseTextDeltaEvent):
                        delta = event.data.delta
                        if delta:
                            yield {
                                "event": "token",
                                "data": json.dumps({"delta": delta}),
                            }
                # Show tool activity
                elif event.type == "run_item_stream_event":
                    item = event.item
                    item_type = getattr(item, "type", "")
                    if item_type == "tool_call_item":
                        raw = getattr(item, "raw_item", None)
                        tool_name = getattr(raw, "name", "") if raw else ""
                        if tool_name:
                            yield {
                                "event": "tool_call",
                                "data": json.dumps({"tool": tool_name, "status": "running"}),
                            }

            # After agent finishes: emit analysis_result for newly analyzed users
            after_analyses: set[str] = set(ctx.analysis_cache.get("x", {}).keys())
            new_users = after_analyses - before_analyses
            for username in new_users:
                x_profile = ctx.profile_cache.get("x", {}).get(username, {})
                x_analysis = ctx.analysis_cache["x"][username]
                if x_profile:
                    yield {
                        "event": "analysis_result",
                        "data": json.dumps({
                            "user_info": x_profile.get("user_info", {}),
                            "tweets": x_profile.get("tweets", []),
                            "patterns": x_profile.get("patterns", {}),
                            "analysis": x_analysis,
                        }, ensure_ascii=False),
                    }

            yield {"event": "done", "data": "{}"}

        except Exception as exc:
            msg = str(exc)
            fix = ""
            if "9377" in msg or "camofox" in msg.lower() or "Connection" in msg:
                fix = "Start Camofox Browser: cd camofox-browser && npm start"
            elif "OPENAI_API_KEY" in msg:
                fix = "Set OPENAI_API_KEY in your .env file"
            yield {
                "event": "error",
                "data": json.dumps({"error": msg, "fix": fix}),
            }

    return EventSourceResponse(_generate())
```

**Step 3: Smoke-test the server starts**

```bash
uv run uvicorn persona_lens.api.server:app --port 8000 --reload
```

Expected: `Uvicorn running on http://127.0.0.1:8000` with no import errors.

**Step 4: Test health endpoint**

```bash
curl http://localhost:8000/api/health
```

Expected: `{"status":"ok"}`

**Step 5: Commit**

```bash
git add persona_lens/api/server.py
git commit -m "feat: add POST /api/chat SSE endpoint with agent streaming"
```

---

## Task 2: Frontend — add chat types to `lib/types.ts`

**Files:**
- Modify: `frontend/lib/types.ts`

**Step 1: Read current types.ts**

```bash
cat frontend/lib/types.ts
```

**Step 2: Append chat types at the end of `frontend/lib/types.ts`**

Add these type definitions after the existing exports:

```typescript
// ── Chat types ──────────────────────────────────────────────────────────────

export interface ToolCallInfo {
  tool: string;
  status: "running" | "done";
}

export interface ChatMessage {
  id: string;
  role: "user" | "agent" | "system";
  content: string;       // accumulated text (built up from token deltas)
  isStreaming: boolean;  // true while receiving tokens
  toolCalls: ToolCallInfo[];
  error?: { error: string; fix: string };
}

export interface ChatState {
  messages: ChatMessage[];
  isStreaming: boolean;
}
```

**Step 3: Verify TypeScript compiles**

```bash
cd frontend && npx tsc --noEmit
```

Expected: no errors.

**Step 4: Commit**

```bash
git add frontend/lib/types.ts
git commit -m "feat: add chat message types"
```

---

## Task 3: Frontend — `useChat` hook

**Files:**
- Create: `frontend/hooks/use-chat.ts`

**Step 1: Create `frontend/hooks/use-chat.ts`**

```typescript
// frontend/hooks/use-chat.ts
"use client";

import { useState, useCallback, useRef, useEffect } from "react";
import type { ChatState, ChatMessage, AnalysisResult } from "@/lib/types";

const API_BASE = "http://localhost:8000";

function makeId(): string {
  return Math.random().toString(36).slice(2, 10);
}

function getOrCreateSessionId(): string {
  if (typeof window === "undefined") return "ssr";
  const key = "persona-lens-session-id";
  let id = localStorage.getItem(key);
  if (!id) {
    id = crypto.randomUUID();
    localStorage.setItem(key, id);
  }
  return id;
}

const WELCOME: ChatMessage = {
  id: "system-welcome",
  role: "system",
  content: "Hi! Ask me to analyze an X/Twitter user, or ask questions about any analyzed profile.",
  isStreaming: false,
  toolCalls: [],
};

interface UseChatOptions {
  onAnalysisResult?: (result: AnalysisResult) => void;
}

export function useChat({ onAnalysisResult }: UseChatOptions = {}) {
  const [state, setState] = useState<ChatState>({
    messages: [WELCOME],
    isStreaming: false,
  });
  const sessionIdRef = useRef<string>("default");

  useEffect(() => {
    sessionIdRef.current = getOrCreateSessionId();
  }, []);

  const sendMessage = useCallback(
    async (text: string) => {
      if (!text.trim()) return;

      const userMsg: ChatMessage = {
        id: makeId(),
        role: "user",
        content: text,
        isStreaming: false,
        toolCalls: [],
      };

      const agentMsgId = makeId();
      const agentMsg: ChatMessage = {
        id: agentMsgId,
        role: "agent",
        content: "",
        isStreaming: true,
        toolCalls: [],
      };

      setState((s) => ({
        messages: [...s.messages, userMsg, agentMsg],
        isStreaming: true,
      }));

      try {
        const res = await fetch(`${API_BASE}/api/chat`, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            message: text,
            session_id: sessionIdRef.current,
          }),
        });

        if (!res.ok || !res.body) {
          throw new Error(`Server error: ${res.status}`);
        }

        const reader = res.body.getReader();
        const decoder = new TextDecoder();
        let buffer = "";

        while (true) {
          const { done, value } = await reader.read();
          if (done) break;
          buffer += decoder.decode(value, { stream: true });

          const lines = buffer.split("\n");
          buffer = lines.pop() ?? "";

          let currentEvent = "";
          for (const line of lines) {
            if (line.startsWith("event: ")) {
              currentEvent = line.slice(7).trim();
            } else if (line.startsWith("data: ")) {
              const rawData = line.slice(6);
              let data: Record<string, unknown>;
              try {
                data = JSON.parse(rawData);
              } catch {
                continue;
              }

              if (currentEvent === "token") {
                const delta = (data.delta as string) ?? "";
                setState((s) => ({
                  ...s,
                  messages: s.messages.map((m) =>
                    m.id === agentMsgId
                      ? { ...m, content: m.content + delta }
                      : m
                  ),
                }));
              } else if (currentEvent === "tool_call") {
                const toolCall = { tool: data.tool as string, status: "running" as const };
                setState((s) => ({
                  ...s,
                  messages: s.messages.map((m) =>
                    m.id === agentMsgId
                      ? { ...m, toolCalls: [...m.toolCalls, toolCall] }
                      : m
                  ),
                }));
              } else if (currentEvent === "analysis_result") {
                onAnalysisResult?.(data as unknown as AnalysisResult);
              } else if (currentEvent === "error") {
                setState((s) => ({
                  ...s,
                  messages: s.messages.map((m) =>
                    m.id === agentMsgId
                      ? { ...m, isStreaming: false, error: data as { error: string; fix: string } }
                      : m
                  ),
                  isStreaming: false,
                }));
              } else if (currentEvent === "done") {
                setState((s) => ({
                  messages: s.messages.map((m) =>
                    m.id === agentMsgId ? { ...m, isStreaming: false } : m
                  ),
                  isStreaming: false,
                }));
              }
              currentEvent = "";
            }
          }
        }
      } catch (err) {
        const errMsg = err instanceof Error ? err.message : String(err);
        setState((s) => ({
          messages: s.messages.map((m) =>
            m.id === agentMsgId
              ? {
                  ...m,
                  isStreaming: false,
                  error: {
                    error: errMsg,
                    fix: "Make sure the FastAPI server is running: uv run uvicorn persona_lens.api.server:app --port 8000",
                  },
                }
              : m
          ),
          isStreaming: false,
        }));
      }
    },
    [onAnalysisResult]
  );

  return { state, sendMessage };
}
```

**Step 2: Verify TypeScript compiles**

```bash
cd frontend && npx tsc --noEmit
```

Expected: no errors.

**Step 3: Commit**

```bash
git add frontend/hooks/use-chat.ts
git commit -m "feat: add useChat hook with SSE streaming and session management"
```

---

## Task 4: Frontend — `ChatMessage` and `ToolCallIndicator` components

**Files:**
- Create: `frontend/components/tool-call-indicator.tsx`
- Create: `frontend/components/chat-message.tsx`

**Step 1: Create `frontend/components/tool-call-indicator.tsx`**

```tsx
// frontend/components/tool-call-indicator.tsx
import type { ToolCallInfo } from "@/lib/types";

const TOOL_LABELS: Record<string, string> = {
  fetch_user: "Fetching tweets\u2026",
  analyze_user: "Running AI analysis\u2026",
};

interface ToolCallIndicatorProps {
  toolCalls: ToolCallInfo[];
}

export function ToolCallIndicator({ toolCalls }: ToolCallIndicatorProps) {
  if (toolCalls.length === 0) return null;
  return (
    <div className="space-y-1 mb-2">
      {toolCalls.map((tc, i) => (
        <div key={i} className="flex items-center gap-2 text-xs text-muted-foreground">
          <span aria-hidden="true">→</span>
          <span>{TOOL_LABELS[tc.tool] ?? `${tc.tool}\u2026`}</span>
        </div>
      ))}
    </div>
  );
}
```

**Step 2: Create `frontend/components/chat-message.tsx`**

```tsx
// frontend/components/chat-message.tsx
import { ToolCallIndicator } from "@/components/tool-call-indicator";
import { ErrorPanel } from "@/components/error-panel";
import type { ChatMessage as ChatMessageType } from "@/lib/types";

interface ChatMessageProps {
  message: ChatMessageType;
}

export function ChatMessage({ message }: ChatMessageProps) {
  const { role, content, isStreaming, toolCalls, error } = message;

  if (role === "system") {
    return (
      <div className="text-xs text-muted-foreground italic px-1 py-2">
        {content}
      </div>
    );
  }

  const isUser = role === "user";

  return (
    <div className={`flex ${isUser ? "justify-end" : "justify-start"}`}>
      <div
        className={`max-w-[85%] rounded-lg px-3 py-2 text-sm ${
          isUser
            ? "bg-primary text-primary-foreground"
            : "bg-muted text-foreground"
        }`}
      >
        {!isUser && <ToolCallIndicator toolCalls={toolCalls} />}
        {content && (
          <p className="whitespace-pre-wrap break-words min-w-0">
            {content}
            {isStreaming && (
              <span className="inline-block w-1.5 h-3.5 ml-0.5 bg-current animate-pulse align-middle" aria-hidden="true" />
            )}
          </p>
        )}
        {!content && isStreaming && !toolCalls.length && (
          <p className="text-muted-foreground/60">Thinking\u2026</p>
        )}
        {error && (
          <div className="mt-2">
            <p className="text-destructive text-xs font-medium">{error.error}</p>
            {error.fix && (
              <p className="text-xs font-mono bg-background/50 rounded px-1 py-0.5 mt-1">
                {error.fix}
              </p>
            )}
          </div>
        )}
      </div>
    </div>
  );
}
```

**Step 3: Verify TypeScript compiles**

```bash
cd frontend && npx tsc --noEmit
```

Expected: no errors.

**Step 4: Commit**

```bash
git add frontend/components/tool-call-indicator.tsx frontend/components/chat-message.tsx
git commit -m "feat: add ChatMessage and ToolCallIndicator components"
```

---

## Task 5: Frontend — `ChatPanel` component

**Files:**
- Create: `frontend/components/chat-panel.tsx`

**Step 1: Create `frontend/components/chat-panel.tsx`**

```tsx
// frontend/components/chat-panel.tsx
"use client";

import { useRef, useEffect, useState, FormEvent, KeyboardEvent } from "react";
import { ChatMessage } from "@/components/chat-message";
import { Button } from "@/components/ui/button";
import { useChat } from "@/hooks/use-chat";
import type { AnalysisResult } from "@/lib/types";

interface ChatPanelProps {
  onAnalysisResult?: (result: AnalysisResult) => void;
}

export function ChatPanel({ onAnalysisResult }: ChatPanelProps) {
  const { state, sendMessage } = useChat({ onAnalysisResult });
  const [input, setInput] = useState("");
  const scrollRef = useRef<HTMLDivElement>(null);

  // Auto-scroll to bottom when messages update
  useEffect(() => {
    const el = scrollRef.current;
    if (el) el.scrollTop = el.scrollHeight;
  }, [state.messages]);

  function handleSubmit(e: FormEvent) {
    e.preventDefault();
    const text = input.trim();
    if (!text || state.isStreaming) return;
    setInput("");
    sendMessage(text);
  }

  function handleKeyDown(e: KeyboardEvent<HTMLTextAreaElement>) {
    if (e.key === "Enter" && !e.shiftKey) {
      e.preventDefault();
      const text = input.trim();
      if (!text || state.isStreaming) return;
      setInput("");
      sendMessage(text);
    }
  }

  return (
    <div className="flex flex-col h-full border rounded-lg overflow-hidden">
      {/* Message list */}
      <div
        ref={scrollRef}
        className="flex-1 overflow-y-auto p-3 space-y-3 overscroll-contain"
        aria-live="polite"
        aria-label="Chat messages"
      >
        {state.messages.map((msg) => (
          <ChatMessage key={msg.id} message={msg} />
        ))}
      </div>

      {/* Input bar */}
      <form
        onSubmit={handleSubmit}
        className="border-t p-2 flex gap-2 items-end"
      >
        <div className="flex-1">
          <label htmlFor="chat-input" className="sr-only">
            Message
          </label>
          <textarea
            id="chat-input"
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyDown={handleKeyDown}
            placeholder="Ask about a KOL, or type 'analyze @username'\u2026"
            autoComplete="off"
            spellCheck={false}
            disabled={state.isStreaming}
            rows={1}
            className="w-full resize-none rounded-md border bg-background px-3 py-2 text-sm placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring disabled:opacity-50"
            style={{ touchAction: "manipulation", maxHeight: "120px" }}
          />
        </div>
        <Button
          type="submit"
          size="sm"
          disabled={!input.trim() || state.isStreaming}
          aria-label="Send message"
          style={{ touchAction: "manipulation" }}
        >
          {state.isStreaming ? "\u22EF" : "Send"}
        </Button>
      </form>
    </div>
  );
}
```

**Step 2: Verify TypeScript compiles**

```bash
cd frontend && npx tsc --noEmit
```

Expected: no errors.

**Step 3: Commit**

```bash
git add frontend/components/chat-panel.tsx
git commit -m "feat: add ChatPanel component"
```

---

## Task 6: Frontend — update `page.tsx` to side-by-side layout

**Files:**
- Modify: `frontend/app/page.tsx`

**Context:** The current `page.tsx` is a full-width single-column layout. We restructure it to:
- Desktop: left 60% analysis panel + right 40% chat panel, both filling the full viewport height
- Mobile (<768px): two tabs — "Results" and "Chat"

The `AnalysisResult` state is lifted up to `AnalysisPage` so both the search bar and chat can update it.

**Step 1: Replace `frontend/app/page.tsx` entirely**

```tsx
// frontend/app/page.tsx
"use client";

import { useEffect, useCallback, useState, Suspense } from "react";
import { useRouter, useSearchParams } from "next/navigation";
import { SearchBar } from "@/components/search-bar";
import { ProgressIndicator } from "@/components/progress-indicator";
import { ProfileCard } from "@/components/profile-card";
import { ProductTags } from "@/components/product-tags";
import { WritingStyle } from "@/components/writing-style";
import { PostingHeatmap } from "@/components/posting-heatmap";
import { TopPosts } from "@/components/top-posts";
import { TweetList } from "@/components/tweet-list";
import { EmptyState } from "@/components/empty-state";
import { ErrorPanel } from "@/components/error-panel";
import { ChatPanel } from "@/components/chat-panel";
import { useAnalysis } from "@/hooks/use-analysis";
import type { AnalysisResult } from "@/lib/types";

type MobileTab = "results" | "chat";

function AnalysisPage() {
  const router = useRouter();
  const params = useSearchParams();
  const { state, analyze } = useAnalysis();
  const [chatResult, setChatResult] = useState<AnalysisResult | null>(null);
  const [mobileTab, setMobileTab] = useState<MobileTab>("results");

  const initialUser = params.get("user") ?? "";
  const initialTweets = Number(params.get("tweets") ?? 30);

  useEffect(() => {
    if (initialUser) {
      analyze(initialUser, initialTweets);
    }
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  const handleAnalyze = useCallback(
    (username: string, tweets: number) => {
      router.push(`/?user=${encodeURIComponent(username)}&tweets=${tweets}`);
      analyze(username, tweets);
    },
    [router, analyze]
  );

  // When chat triggers an analysis, switch to results tab on mobile and update result
  const handleChatAnalysis = useCallback((result: AnalysisResult) => {
    setChatResult(result);
    setMobileTab("results");
  }, []);

  // The displayed result: search bar result takes priority, then chat result
  const { status, progress, result: searchResult, error } = state;
  const displayResult = searchResult ?? chatResult;

  // ── Analysis panel content ───────────────────────────────────────────────
  const analysisContent = (
    <div className="flex flex-col h-full overflow-y-auto space-y-4 pr-1">
      <SearchBar
        onAnalyze={handleAnalyze}
        isLoading={status === "loading"}
        initialUsername={initialUser}
        initialTweets={initialTweets}
      />

      {status === "idle" && !chatResult && <EmptyState />}

      {status === "loading" && progress && (
        <ProgressIndicator stage={progress.stage} message={progress.message} />
      )}

      {status === "error" && error && (
        <ErrorPanel
          error={error.error}
          fix={error.fix}
          onRetry={() => {
            const u = params.get("user") ?? "";
            const t = Number(params.get("tweets") ?? 30);
            if (u) analyze(u, t);
          }}
        />
      )}

      {displayResult && (
        <div className="space-y-4">
          <div className="grid grid-cols-1 gap-4 sm:grid-cols-2">
            <ProfileCard
              userInfo={displayResult.user_info}
              tweetsParsed={displayResult.tweets.length}
            />
            <ProductTags products={displayResult.analysis.products} />
          </div>

          <div className="grid grid-cols-1 gap-4 sm:grid-cols-2">
            <WritingStyle text={displayResult.analysis.writing_style} />
            <PostingHeatmap
              peakDays={displayResult.patterns.peak_days}
              peakHours={displayResult.patterns.peak_hours}
            />
          </div>

          <TopPosts
            insights={displayResult.analysis.engagement.insights}
            topPosts={displayResult.analysis.engagement.top_posts}
          />

          <TweetList
            tweets={displayResult.tweets}
            username={displayResult.user_info.username}
          />
        </div>
      )}
    </div>
  );

  return (
    <div className="flex flex-col h-screen">
      {/* Skip link */}
      <a
        href="#main-content"
        className="sr-only focus:not-sr-only focus:absolute focus:top-2 focus:left-2 focus:z-50 focus:rounded focus:bg-background focus:px-3 focus:py-2 focus:text-sm focus:ring-2 focus:ring-ring"
      >
        Skip to content
      </a>

      <header className="px-4 py-3 border-b shrink-0">
        <h1 className="text-lg font-bold tracking-tight">Persona Lens</h1>
      </header>

      {/* ── Desktop: side-by-side ── */}
      <main
        id="main-content"
        className="hidden md:flex flex-1 overflow-hidden gap-0"
      >
        {/* Left: analysis panel */}
        <div className="w-3/5 overflow-y-auto p-4 border-r">
          {analysisContent}
        </div>

        {/* Right: chat panel */}
        <div className="w-2/5 p-3 flex flex-col">
          <ChatPanel onAnalysisResult={handleChatAnalysis} />
        </div>
      </main>

      {/* ── Mobile: tab switching ── */}
      <div className="md:hidden flex flex-col flex-1 overflow-hidden">
        {/* Tab bar */}
        <div
          role="tablist"
          aria-label="View"
          className="flex border-b shrink-0"
        >
          <button
            role="tab"
            aria-selected={mobileTab === "results"}
            aria-controls="panel-results"
            onClick={() => setMobileTab("results")}
            className={`flex-1 py-2 text-sm font-medium transition-colors ${
              mobileTab === "results"
                ? "border-b-2 border-primary text-primary"
                : "text-muted-foreground"
            }`}
            style={{ touchAction: "manipulation" }}
          >
            Results
          </button>
          <button
            role="tab"
            aria-selected={mobileTab === "chat"}
            aria-controls="panel-chat"
            onClick={() => setMobileTab("chat")}
            className={`flex-1 py-2 text-sm font-medium transition-colors ${
              mobileTab === "chat"
                ? "border-b-2 border-primary text-primary"
                : "text-muted-foreground"
            }`}
            style={{ touchAction: "manipulation" }}
          >
            Chat
          </button>
        </div>

        {/* Tab panels */}
        <div
          id="panel-results"
          role="tabpanel"
          hidden={mobileTab !== "results"}
          className="flex-1 overflow-y-auto p-4"
        >
          {analysisContent}
        </div>
        <div
          id="panel-chat"
          role="tabpanel"
          hidden={mobileTab !== "chat"}
          className="flex-1 overflow-hidden p-3 flex flex-col"
        >
          <ChatPanel onAnalysisResult={handleChatAnalysis} />
        </div>
      </div>
    </div>
  );
}

export default function Home() {
  return (
    <Suspense fallback={<div className="h-screen" />}>
      <AnalysisPage />
    </Suspense>
  );
}
```

**Step 2: Run TypeScript check**

```bash
cd frontend && npx tsc --noEmit
```

Expected: no errors.

**Step 3: Run production build**

```bash
cd frontend && npm run build
```

Expected: build completes successfully. If there are Tailwind v4 class errors, check that class names like `w-3/5` and `w-2/5` are valid (they are standard Tailwind utilities).

**Step 4: Commit**

```bash
git add frontend/app/page.tsx
git commit -m "feat: restructure page to side-by-side analysis + chat layout"
```

---

## Task 7: Final verification

**Step 1: Start full stack**

```bash
# Terminal 1: Camofox Browser (must already be running)

# Terminal 2:
uv run uvicorn persona_lens.api.server:app --port 8000 --reload

# Terminal 3:
cd frontend && npm run dev
```

**Step 2: Verification checklist**

- [ ] http://localhost:3000 shows two-panel layout on desktop (analysis left, chat right)
- [ ] Chat panel shows welcome message on load
- [ ] Typing "analyze @elonmusk" in chat → Agent responds, left panel updates with results
- [ ] Typing "what products does he mention?" → Agent answers from cached context (no re-fetch)
- [ ] Search bar in left panel still works independently
- [ ] On mobile (<768px): Results / Chat tab switching works
- [ ] `aria-live="polite"` region updates as tokens stream in
- [ ] Tab key navigates through interactive elements correctly
- [ ] Dark mode works in both panels

**Step 3: Run Python tests**

```bash
uv run pytest tests/ -v
```

Expected: all 35 tests pass.

**Step 4: Final commit**

```bash
git add .
git commit -m "feat: complete chat feature with side-by-side layout"
```
